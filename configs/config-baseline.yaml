hydra:
  job:
    chdir: False

train:
  dataset_name: ["JasiekKaczmarczyk/giant-midi-sustain-masked", "JasiekKaczmarczyk/pianofor-ai-sustain-masked", "JasiekKaczmarczyk/maestro-v1-sustain-masked"] # huggingface dataset
  batch_size: 512
  num_workers: 8
  lr: 3e-5
  weight_decay: 0.01
  pitch_shift_probability: 0.5
  time_stretch_probability: 0.5
  num_epochs: 20
  device: "cuda"
  precision: "16-mixed" # not implemented yet
  overfit_single_batch: False
  use_gradnorm: True
  gn_restoring_force: 1.5
  masking_ratio_scheduler:
    0: 0.15
    6e8: 0.2
    12e8: 0.25
    18e8: 0.3
    24e8: 0.35
    30e8: 0.4
    36e8: 0.45
    42e8: 0.5
  loss_lambdas:
    pitch: 1.
    velocity: 1.
    start: 1.
    duration: 1.


model:
  encoder_dim: 512
  encoder_depth: 6
  encoder_num_heads: 8
  decoder_dim: 384
  decoder_depth: 4
  decoder_num_heads: 8
  mlp_ratio: 3.
  dynamics_embedding_depth: 4

paths:
  save_ckpt_dir: "checkpoints" # directory where checkpoints will be saved
  load_ckpt_path: null # if not None, specifies path to model state dict which will be loaded
  log_dir: "logs"
  hf_repo_id: null # repo id to upload model to huggingface if null model is not uploaded

logger:
  run_name: mae-baseline-${now:%Y-%m-%d-%H-%M}
  log_every_n_steps: 10
